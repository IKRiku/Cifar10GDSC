# -*- coding: utf-8 -*-
"""MLGDSC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vK51VeaO6Bt9MNKzf3mEz4qEsFCZFT8w
"""

# Import libraries
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import numpy as np

# load CIFAR-10 dataset
(xtr, ytr), (xte, yte) = cifar10.load_data()

# normalize pixel values to [0, 1]
xtr = xtr.astype('float32') / 255.0
xte = xte.astype('float32') / 255.0

# convert labels to one-hot encoding
ytr = to_categorical(ytr, 10)
yte = to_categorical(yte, 10)

# split training data into training and validation sets
xtr, xval, ytr, yval = train_test_split(xtr, ytr, test_size=0.2, random_state=42)

# build CNN model
def build_cnn(shp=(32, 32, 3)):
    mdl = models.Sequential()
    mdl.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=shp))
    mdl.add(layers.BatchNormalization())
    mdl.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
    mdl.add(layers.BatchNormalization())
    mdl.add(layers.MaxPooling2D((2, 2)))
    mdl.add(layers.Dropout(0.2))

    mdl.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
    mdl.add(layers.BatchNormalization())
    mdl.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
    mdl.add(layers.BatchNormalization())
    mdl.add(layers.MaxPooling2D((2, 2)))
    mdl.add(layers.Dropout(0.3))

    mdl.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    mdl.add(layers.BatchNormalization())
    mdl.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    mdl.add(layers.BatchNormalization())
    mdl.add(layers.MaxPooling2D((2, 2)))
    mdl.add(layers.Dropout(0.4))

    mdl.add(layers.Flatten())
    mdl.add(layers.Dense(128, activation='relu'))
    mdl.add(layers.BatchNormalization())
    mdl.add(layers.Dropout(0.5))
    mdl.add(layers.Dense(10, activation='softmax'))

    return mdl

mdl = build_cnn()

# compile model
opt = optimizers.Adam(learning_rate=0.001)
mdl.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

# early stopping and learning rate scheduler
es = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)

# train model
hist = mdl.fit(xtr, ytr, epochs=100, batch_size=64, validation_data=(xval, yval), callbacks=[es, lr])

# evaluate model
loss, acc = mdl.evaluate(xte, yte)
print(f'Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')

# predict and generate classification report
ypred = mdl.predict(xte)
ypred_cls = np.argmax(ypred, axis=1)
ytrue = np.argmax(yte, axis=1)
print(classification_report(ytrue, ypred_cls))

# plot accuracy and loss curves
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(hist.history['accuracy'], label='Train Acc')
plt.plot(hist.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title('Accuracy Curves')

plt.subplot(1, 2, 2)
plt.plot(hist.history['loss'], label='Train Loss')
plt.plot(hist.history['val_loss'], label='Val Loss')
plt.legend()
plt.title('Loss Curves')
plt.show()

# transfer Learning with VGG16
base_mdl = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))

# freeze VGG16 layers
for layer in base_mdl.layers:
    layer.trainable = False

# build transfer learning model
t_mdl = models.Sequential()
t_mdl.add(base_mdl)
t_mdl.add(layers.Flatten())
t_mdl.add(layers.Dense(256, activation='relu'))
t_mdl.add(layers.BatchNormalization())
t_mdl.add(layers.Dropout(0.5))
t_mdl.add(layers.Dense(10, activation='softmax'))

# compile transfer model
t_mdl.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# train transfer model
t_hist = t_mdl.fit(xtr, ytr, epochs=50, batch_size=64, validation_data=(xval, yval), callbacks=[es, lr])

# evaluate transfer model
t_loss, t_acc = t_mdl.evaluate(xte, yte)
print(f'Transfer Test Loss: {t_loss:.4f}, Transfer Test Accuracy: {t_acc:.4f}')

# predict and generate classification report for transfer model
yt_pred = t_mdl.predict(xte)
yt_pred_cls = np.argmax(yt_pred, axis=1)
print(classification_report(ytrue, yt_pred_cls))

"""# New Section"""